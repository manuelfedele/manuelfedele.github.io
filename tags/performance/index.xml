<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Performance on Git Push and Run</title><link>https://manuelfedele.github.io/tags/performance/</link><description>Recent content in Performance on Git Push and Run</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2026 Manuel Fedele</copyright><lastBuildDate>Thu, 29 Dec 2022 10:19:25 +0100</lastBuildDate><atom:link href="https://manuelfedele.github.io/tags/performance/index.xml" rel="self" type="application/rss+xml"/><item><title>Python Generators and yield: Building Memory-Efficient Pipelines</title><link>https://manuelfedele.github.io/posts/what-does-yield-keyword-do-in-python/</link><pubDate>Thu, 29 Dec 2022 10:19:25 +0100</pubDate><guid>https://manuelfedele.github.io/posts/what-does-yield-keyword-do-in-python/</guid><description>&lt;div class="lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl">
 A generator is a lazy sequence. It produces values one at a time on demand instead of materializing everything into memory at once. For large datasets, streaming APIs, and data processing pipelines, generators are the correct default, not an optimization applied after the fact.
&lt;/div>

&lt;p>Python generators are one of the most practically useful features in the language, and one of the most underused by engineers who learned Python from web tutorials. This post goes beyond &amp;ldquo;use yield instead of return&amp;rdquo; and covers the full picture: the iterator protocol, memory characteristics, &lt;code>yield from&lt;/code>, generator pipelines, and real-world streaming use cases.&lt;/p></description></item></channel></rss>