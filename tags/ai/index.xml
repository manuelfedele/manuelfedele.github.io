<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI on Git Push and Run</title><link>https://manuelfedele.github.io/tags/ai/</link><description>Recent content in AI on Git Push and Run</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>© 2026 Manuel Fedele</copyright><lastBuildDate>Sun, 01 Mar 2026 12:00:00 +0100</lastBuildDate><atom:link href="https://manuelfedele.github.io/tags/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>Leveraging AI as a Software Engineer: What Actually Works</title><link>https://manuelfedele.github.io/posts/leveraging-ai-as-a-platform-engineer/</link><pubDate>Sun, 01 Mar 2026 12:00:00 +0100</pubDate><guid>https://manuelfedele.github.io/posts/leveraging-ai-as-a-platform-engineer/</guid><description>&lt;div class="lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl">
 I have been using AI coding assistants seriously for about a year — not casually, not experimentally, but as a core part of how I do my job every day. This is not a post about AI generating code. It is about how AI changes the way an experienced engineer thinks, investigates, and makes decisions.
&lt;/div>


&lt;h2 class="relative group">The Shift That Actually Matters
 &lt;div id="the-shift-that-actually-matters" class="anchor">&lt;/div>
 
 &lt;span
 class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
 &lt;a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#the-shift-that-actually-matters" aria-label="Anchor">#&lt;/a>
 &lt;/span>
 
&lt;/h2>
&lt;p>The naive version of AI-assisted development is: you describe what you want, the AI writes it, you review and move on. This is real and useful, but it is also the least interesting thing AI does for me.&lt;/p></description></item><item><title>Building an AI SRE Assistant From Scratch: Architecture of an Autonomous Infrastructure Investigator</title><link>https://manuelfedele.github.io/posts/building-ai-sre-assistant-from-scratch/</link><pubDate>Sun, 22 Feb 2026 09:30:00 +0100</pubDate><guid>https://manuelfedele.github.io/posts/building-ai-sre-assistant-from-scratch/</guid><description>&lt;h1 class="relative group">Building an AI SRE Assistant From Scratch: Architecture of an Autonomous Infrastructure Investigator
 &lt;div id="building-an-ai-sre-assistant-from-scratch-architecture-of-an-autonomous-infrastructure-investigator" class="anchor">&lt;/div>
 
 &lt;span
 class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
 &lt;a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#building-an-ai-sre-assistant-from-scratch-architecture-of-an-autonomous-infrastructure-investigator" aria-label="Anchor">#&lt;/a>
 &lt;/span>
 
&lt;/h1>
&lt;p>What if your on-call engineer never slept, had instant access to every repository and every AWS account, and could trace a production issue from DNS to database in under a minute?&lt;/p>
&lt;p>That&amp;rsquo;s the question that led me to build TARS, an AI-powered SRE assistant that autonomously investigates infrastructure issues by combining LLM reasoning with deep integrations into GitLab and AWS. Named after the robot from Interstellar (because every good internal tool needs a movie reference), TARS is a full-stack application where engineers interact with an AI agent through a chat interface. The agent doesn&amp;rsquo;t just answer questions. It investigates. It clones repos, greps code, reads CloudWatch logs, traces DNS chains, inspects ECS services, and synthesizes findings into structured reports.&lt;/p></description></item><item><title>Building an AI-Powered Platform Operations Agent</title><link>https://manuelfedele.github.io/posts/building-ai-powered-platform-operations-agent/</link><pubDate>Sun, 15 Feb 2026 11:00:00 +0100</pubDate><guid>https://manuelfedele.github.io/posts/building-ai-powered-platform-operations-agent/</guid><description>&lt;h1 class="relative group">Building an AI-Powered Platform Operations Agent
 &lt;div id="building-an-ai-powered-platform-operations-agent" class="anchor">&lt;/div>
 
 &lt;span
 class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
 &lt;a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#building-an-ai-powered-platform-operations-agent" aria-label="Anchor">#&lt;/a>
 &lt;/span>
 
&lt;/h1>
&lt;p>Platform engineering teams handle a constant stream of repetitive requests: onboarding users, managing API keys, checking service health, rotating credentials. Most of these tasks follow well-defined procedures that a human executes step by step. What if an AI agent could handle them instead?&lt;/p>
&lt;p>In this post, I&amp;rsquo;ll walk through the architecture of an AI-powered operations agent that automates common platform tasks by giving an LLM access to your internal tools through a structured tool-calling interface.&lt;/p></description></item><item><title>Building an AI-Powered Document Processing Pipeline on AWS</title><link>https://manuelfedele.github.io/posts/building-ai-document-processing-pipeline-aws/</link><pubDate>Wed, 03 Dec 2025 16:45:00 +0100</pubDate><guid>https://manuelfedele.github.io/posts/building-ai-document-processing-pipeline-aws/</guid><description>&lt;h1 class="relative group">Building an AI-Powered Document Processing Pipeline on AWS
 &lt;div id="building-an-ai-powered-document-processing-pipeline-on-aws" class="anchor">&lt;/div>
 
 &lt;span
 class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
 &lt;a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#building-an-ai-powered-document-processing-pipeline-on-aws" aria-label="Anchor">#&lt;/a>
 &lt;/span>
 
&lt;/h1>
&lt;p>Insurance companies process millions of documents every year: police reports, medical records, invoices, repair estimates. Traditionally, human operators read each document, classify it, extract the relevant fields, and enter the data into the claims system. This is slow, expensive, and error-prone.&lt;/p>
&lt;p>In this post I&amp;rsquo;ll describe the architecture of a production document processing pipeline I helped build. The system ingests claim documents, extracts text using vision-based LLMs, clusters and classifies document sections, extracts structured data, and generates vector embeddings for semantic search. All of this runs on a fully serverless AWS architecture with no idle infrastructure costs.&lt;/p></description></item></channel></rss>